{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebd46f4",
   "metadata": {},
   "source": [
    "# Solving optimal control problems with policy gradient method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.patches as patches\n",
    "font = font_manager.FontProperties(style='normal', size=20)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.set_default_dtype(torch.float32) # improved the speed when the parameters are float32\n",
    "import random\n",
    "\n",
    "import json\n",
    "\n",
    "from IPython.display import display, Math, Markdown\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "timestamp\n",
    "version = '_0.1.0'\n",
    "import math\n",
    "PI = math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb9fdfd",
   "metadata": {},
   "source": [
    "## Defining control by a neural network\n",
    "\n",
    "$$\\phi(t,x;\\theta)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dd6e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 20 # Modify the number of neurons\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, num_neurons),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(num_neurons,1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af3ded",
   "metadata": {},
   "source": [
    "## Predefine global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3a83fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # number of time steps\n",
    "T = 1.0 # terminal time\n",
    "dt = T/N # time step\n",
    "num_samples = 1_000 # Modify the number of samples\n",
    "x0 = 2*torch.rand([num_samples,1]) -1 # initial condition uniformly random in [-1,1]\n",
    "dW = torch.sqrt(torch.tensor(dt))*torch.randn([num_samples,N,1]) # Brownian increments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf6f6b",
   "metadata": {},
   "source": [
    "## State variable\n",
    "\n",
    "$$dX_t = (x_t-u_t)dt + dW_t$$\n",
    "\n",
    "$$u_t=\\phi(t,x_t,\\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76ca6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update function\n",
    "def update(t,x,u):\n",
    "    return x + (x -  u)*dt + dW[:,t,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d72170",
   "metadata": {},
   "source": [
    "## Loss function \n",
    "\n",
    "$$C(x,u)=x^2+x+u^2$$\n",
    "\n",
    "$$g(x)=x^2-x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0601568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_loss(t,x,model):\n",
    "    u = model(x)\n",
    "    return torch.mean(x**2+x+u**2)*dt\n",
    "\n",
    "def total_loss(model):\n",
    "    x = x0\n",
    "    running_cost = 0.0\n",
    "    for t in range(N):\n",
    "        u = model(x)\n",
    "        running_cost = running_cost + step_loss(t,x,model)\n",
    "        x = update(t,x,u)\n",
    "    terminal_cost = torch.mean(x**2 - x)\n",
    "    total_loss = running_cost + terminal_cost\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c780775d",
   "metadata": {},
   "source": [
    "## Generate the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c386b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(6.7341, grad_fn=<AddBackward0>)\n",
      "2 tensor(2.6102, grad_fn=<AddBackward0>)\n",
      "4 tensor(2.8496, grad_fn=<AddBackward0>)\n",
      "6 tensor(3.1038, grad_fn=<AddBackward0>)\n",
      "8 tensor(3.0079, grad_fn=<AddBackward0>)\n",
      "10 tensor(2.7307, grad_fn=<AddBackward0>)\n",
      "12 tensor(2.5654, grad_fn=<AddBackward0>)\n",
      "14 tensor(2.5935, grad_fn=<AddBackward0>)\n",
      "16 tensor(2.7156, grad_fn=<AddBackward0>)\n",
      "18 tensor(2.6161, grad_fn=<AddBackward0>)\n",
      "20 tensor(2.5395, grad_fn=<AddBackward0>)\n",
      "22 tensor(2.5640, grad_fn=<AddBackward0>)\n",
      "24 tensor(2.5992, grad_fn=<AddBackward0>)\n",
      "26 tensor(2.5900, grad_fn=<AddBackward0>)\n",
      "28 tensor(2.5492, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "# optimizer2 = optim.SGD(model.parameters(), learning_rate,momentum=0.9)\n",
    "for t in range(num_epochs):\n",
    "    loss = total_loss(model)#.clone().detach().requires_grad_(True)\n",
    "    optimizer.zero_grad() # Zero the gradients before running the backward pass.\n",
    "    loss.backward() # Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "    if t % 2 == 0:\n",
    "        print(t, loss)\n",
    "    optimizer.step() # Update the weights and biases using gradient descent. Each parameter is a Tensor. Equivalent to the above three lines, but more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3364299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
