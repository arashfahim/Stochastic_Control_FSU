{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arashfahim/Stochastic_Control_FSU/blob/main/Deep_BSDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/arashfahim/Stochastic_Control_FSU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYpsD_vHtIpa",
        "outputId": "5dcbdf02-7a9e-4f3a-e95d-9c7278cb88ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Stochastic_Control_FSU'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 111 (delta 3), reused 2 (delta 2), pack-reused 97\u001b[K\n",
            "Receiving objects: 100% (111/111), 2.84 MiB | 6.56 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcK8F3qLthk9",
        "outputId": "c8a7e6f5-1bb9-4d54-90ab-4cee184755a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Dec  4 14:27 sample_data\n",
            "drwxr-xr-x 4 root root 4096 Dec  7 14:40 Stochastic_Control_FSU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'/content/Stochastic_Control_FSU/arashfahim/Stochastic_Control_FSU/'"
      ],
      "metadata": {
        "id": "gDKJJU8n5db3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix4wczxVvVD8",
        "outputId": "0204497b-d094-4889-84f7-e38910dcf118"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sotchastic control and BSDEs\n",
        "\n",
        "The goal of this notebook is to implement a BSDE dynamic programming principle, DPP, for a stochastic control problem.\n",
        "\n",
        "The stochastic control problem is given by\n",
        "\n",
        "$\\inf_{u}\\mathbb{E}\\bigg[\\int_{0}^{T}e^{-rt}C(t,X^u_t,u_t)dt+e^{-rT}g(X^u_T)\\bigg]$\n",
        "\n",
        "with\n",
        "\n",
        "$dX_t=\\mu(t,X^u_t,u_t)dt+\\sigma(t,X^u_t,u_t)dB_t$\n",
        "\n"
      ],
      "metadata": {
        "id": "Hq2eZ_d-UDNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assume that $\\sigma$ does not depend on $u$. When $\\sigma$ depends on $u$, the BSDE is second order and more involve.\n",
        "\n",
        "$dX^u_t=\\mu(t,X^u_t,u_t)dt+\\sigma(t,X^u_t)dB_t$\n",
        "\n",
        "The HJB is given by\n",
        "\n",
        "$\\begin{cases}\n",
        "\\partial_t V(t,x) + \\frac{\\sigma^2(t,x)}{2}\\partial^2_x V(t,x) -rV(t,x) + F(t,x,\\partial_x V(t,x))=0\\\\\n",
        "V(T,x)=g(x)\n",
        "\\end{cases}$\n",
        "\n",
        "where\n",
        "\n",
        "$F(t,x,p)=\\inf_u\\Big\\{C(t,x,u)+p\\mu(t,x,u)\\Big\\}$\n",
        "\n",
        "\n",
        "The BSDE is given by\n",
        "\n",
        "\n",
        "$Y_t=Y_T+\\int_t^T e^{-r(s-t)}\\Big(F(s,X_s,Z_s)dt-Z_s\\sigma(s,X_s)dB_s\\Big)$\n",
        "\n",
        "Or\n",
        "\n",
        "$\\begin{cases}\n",
        "dY_t=-F(t,X_t,Z_t)dt+Z_t\\sigma(t,X_t)dB_t\\\\\n",
        "Y_T=g(X_T)\n",
        "\\end{cases}$\n",
        "\n",
        "where $dX_t=\\sigma(t,X_t)dB_t$ is free of control.\n",
        "\n",
        "\n",
        "$Y_t$ and $Z_t$ are related to the solution to the HJB by $Y_t=V(t,X_t)$ and $Z_t=\\partial_x V(t,X_t)$.\n",
        "\n",
        "\n",
        "Note that here both $Y$ and $Z$ are unknowns. Particularly, $Y_0=V(0,X_0)$ is not known."
      ],
      "metadata": {
        "id": "JP7f4T78Uqvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical approximation of PDEs with BSDEs\n",
        "\n",
        "We discretize the BSDE:\n",
        "\n",
        "\n",
        "$\\begin{cases}\n",
        "Y_{t_{i+1}}= Y_{t_i}-F({t_i},X_{t_i},Z_{t_i})dt+Z_{t_i}\\sigma({t_i},X_{t_i})\\Delta B_{t_{t+1}}\\\\\n",
        "Y_T=g(X_T)\n",
        "\\end{cases}$\n",
        "\n",
        "where $X_{t_{i+1}}=X_{t_i}+\\sigma(t_i,X_{t_i})\\Delta B_{t_{t+1}}$\n",
        "\n",
        "If $\\hat{Y}$ is an approximate solution to the BSDE through the above method, $\\hat{Y}_{t_i}$ is an approximation of $V(t_i,X_{t_i})$. Specifically, if we start from  $\\hat{Y}_{0}$ and run the discretize BSDE forward, instead of backward, we must obtain $g(X_T)$ at time $T$.\n",
        "\n",
        "This is a basis for the deep numerical solution for the BSDE. Let's introduce two neural networks ${\\hat Y}_{t}=\\Phi(t,x;\\alpha)$ and ${\\hat Z}_{t}=\\Psi(t,x;\\beta)$.\n",
        "\n",
        "\n",
        "Then, simulate $X_0$ by some distribution and increment of Brownina motion to find sample paths through ${\\hat X}_{t_{i+1}}={\\hat X}_{t_i}+\\sigma(t_i,{\\hat X}_{t_i})\\Delta B_{t_{t+1}}$.\n",
        "\n",
        "Then, run the BSDE discretization forward in time:\n",
        "\n",
        "\n",
        "$\\Phi(t_{i+1},{\\hat X}_{t_{i+1}};\\alpha)= \\Phi(t_i,{\\hat X}_{t_{i}};\\alpha)-F\\big({t_i},{\\hat X}_{t_i},\\Psi({t_i},{\\hat X}_{t_i};\\beta)\\big)\\Delta t+\\Psi(t_{i},{\\hat X}_{t_i};\\beta)\\sigma({t_i},{\\hat X}_{t_i})\\Delta B_{t_{t+1}}$\n",
        "\n",
        "\n",
        "Finally, find optimal $\\alpha$ and $\\beta$ by\n",
        "\n",
        "$\\inf_{\\alpha,\\beta}\\mathbb{E}\\Big[\\Big(g({\\hat X}_T)-\\Phi_T({\\hat X}_{T};\\alpha)\\Big)\\Big]$"
      ],
      "metadata": {
        "id": "gWlxVOtcrwrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from time import strftime, localtime\n",
        "import torch.optim as optim #import optimizer\n",
        "# import torch.optim.lr_scheduler as lr_scheduler\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "M =10000# number of samples\n",
        "X = torch.normal(0., 1., size=(M,1))# samples for X~N(0,1)\n",
        "Y = torch.exp(-X)+torch.exp(X)*torch.normal(0., 1., size=(M,1))# samples for Y=e^{-x}+e^{x}N(0,1)\n",
        "# X.shape\n",
        "T=1# terminal horizon\n",
        "N = 10 # of time steps\n",
        "Dt= torch.Tensor([T/N])# time step size"
      ],
      "metadata": {
        "id": "-Obh3NNKOTMI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create time stamp to save the result\n",
        "stamp = strftime('%Y-%m-%d %H:%M:%S', localtime())\n",
        "print(str(stamp))"
      ],
      "metadata": {
        "id": "5hwEP5QcSA4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08cf5fa-715e-4d60-9f1e-5166fd8b180e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 14:41:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All at once"
      ],
      "metadata": {
        "id": "HQI-rsqSiGQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Z_NN(nn.Module):#multi_step, optimal_control\n",
        "    def __init__(self):\n",
        "        super(Z_NN, self).__init__()\n",
        "        self.layer = torch.nn.Sequential()\n",
        "        self.layer.add_module(\"L1\",torch.nn.Linear(2, 16))\n",
        "        self.layer.add_module(\"Tanh\", torch.nn.Tanh())\n",
        "        self.layer.add_module(\"L2\",torch.nn.Linear(16,1))\n",
        "    def forward(self, tx):\n",
        "        val = self.layer(tx)\n",
        "        return val"
      ],
      "metadata": {
        "id": "SIpEW8y9ztpK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Y_NN(nn.Module):#multi_step, optimal_control\n",
        "    def __init__(self):\n",
        "        super(Y_NN, self).__init__()\n",
        "        self.layer = torch.nn.Sequential()\n",
        "        self.layer.add_module(\"L1\",torch.nn.Linear(1, 16))\n",
        "        self.layer.add_module(\"Tanh\", torch.nn.Tanh())\n",
        "        self.layer.add_module(\"L2\",torch.nn.Linear(16,1))\n",
        "    def forward(self, tx):\n",
        "        val = self.layer(tx)\n",
        "        return val"
      ],
      "metadata": {
        "id": "LVLBBho925O3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BSDE(classmethod):#multi_step, optimal_control\n",
        "    def __init__(self,terminal):\n",
        "        self.Y_NN = Y_NN()\n",
        "        self.Z_NN = Z_NN()\n",
        "        self.M = 1000# number of samples\n",
        "        self.Te=1.0 # terminal time\n",
        "        self.K = 20 # total number of steps\n",
        "        self.Dt= torch.Tensor([self.Te/self.K]) #time step\n",
        "        self.num_steps = 5 #number of steps to evaluate <= self.K\n",
        "        # self.N = torch.normal(0., 1., size=[self.M,self.num_steps,1])\n",
        "        self.terminal = terminal # terminal value function\n",
        "        self.X0 = torch.normal(0., 1., size=(self.M,1))\n",
        "        for i in range(self.K):# create time data points\n",
        "            if i == 0:\n",
        "                T = torch.Tensor([0.0]).repeat([self.M,1])\n",
        "            else:\n",
        "                D = i*self.Dt# time step i\n",
        "                T = torch.cat((T,D.repeat([self.M,1])),axis=1)\n",
        "        self.T = T.unsqueeze(2)\n",
        "        self.B = torch.normal(0., 1., size=(self.M,self.K,1))\n",
        "        for i in range(self.K-self.num_steps,self.K):\n",
        "                if i == self.K-self.num_steps:\n",
        "                    update = torch.cat((self.T[:,i],self.X0),axis=1)# cat time and space\n",
        "                    self.TX = update.unsqueeze(-1) # add dimension fot bmm\n",
        "                else:\n",
        "                    X = update[:,1].unsqueeze(-1)# slice space for update\n",
        "                    X = X +  torch.sqrt(self.Dt)*self.B[:,i-1] #update, += is prohibited here because it fundamentally change\n",
        "                    update = torch.cat((self.T[:,i],X),axis=1) # cat  time and space\n",
        "                    self.TX = torch.cat((self.TX,update.unsqueeze(-1)),axis=-1) # cat to previous data\n",
        "        X = update[:,1].unsqueeze(-1) #slice last space\n",
        "        X = X +  torch.sqrt(self.Dt)*self.B[:,-1]# last update, += is prohibited here\n",
        "        update = torch.cat((torch.Tensor([self.Te]).repeat([self.M,1]),X),axis=1) # last cat\n",
        "        self.TX = torch.cat((self.TX,update.unsqueeze(-1)),axis=-1) #last cat to previous data\n",
        "\n",
        "    def F(self,tx):#take a [N,1] tensor\n",
        "        # tx = torch.cat((t,x),axis=1)\n",
        "        return torch.Tensor([0.5])*torch.pow(self.Z_NN.forward(tx),2)-self.Z_NN.forward(tx)*(tx[:,1].unsqueeze(-1))\n",
        "\n",
        "    def loss(self):\n",
        "        for i in range(self.K-self.num_steps,self.K):\n",
        "                if i == self.K-self.num_steps:\n",
        "                    # print(self.TX[:,1,0].shape)\n",
        "                    Y = self.Y_NN(self.TX[:,1,0].unsqueeze(-1))\n",
        "                else:\n",
        "                    # print(self.TX[:,:,i-self.K+self.num_steps].shape,self.Z_NN(self.TX[:,:,i-self.K+self.num_steps]).shape,self.B[:,i-1].shape)\n",
        "                    Y = Y + self.F(self.TX[:,:,i-self.K+self.num_steps])*self.Dt + self.Z_NN(self.TX[:,:,i-self.K+self.num_steps])*self.B[:,i-1]\n",
        "        Y = Y + self.F(self.TX[:,:,-1])*self.Dt + self.Z_NN(self.TX[:,:,-1])*self.B[:,-1]\n",
        "        return torch.mean(torch.pow(self.terminal(self.TX[:,1,-1]).unsqueeze(-1)-Y,2)) #mean value of running and terminal"
      ],
      "metadata": {
        "id": "bnapNc3rf26o"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class terminal(nn.Module):\n",
        "    def __init__(self,flag,*args):\n",
        "        super(terminal, self).__init__()\n",
        "        self.layer = torch.nn.Sequential()\n",
        "        self.layer.add_module(\"L1\",torch.nn.Linear(1, 16))\n",
        "        self.layer.add_module(\"Tanh\", torch.nn.Tanh())\n",
        "        self.layer.add_module(\"L2\",torch.nn.Linear(16,1))\n",
        "        self.flag = flag\n",
        "    def forward(self, x):\n",
        "        if self.flag == 'T':\n",
        "            return torch.Tensor([0.5])*torch.pow(x,2)-x\n",
        "        else:\n",
        "            val = self.layer(x)\n",
        "            return val\n",
        "        return x"
      ],
      "metadata": {
        "id": "bDi5DZgc5DT9"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = terminal('T')\n",
        "v2 = BSDE(g)\n",
        "# v2.value()"
      ],
      "metadata": {
        "id": "arVD0owsiSYM"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.autograd.set_detect_anomaly(True);"
      ],
      "metadata": {
        "id": "i_O95kDKki9s"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_epoch = []\n",
        "num_epochs = 1000\n",
        "lr = 1e-2\n",
        "parameters = list(v2.Y_NN.parameters()) + list(v2.Z_NN.parameters())\n",
        "optimizer2 = optim.Adam(parameters, lr)\n",
        "L_ = torch.Tensor([-2.0])\n",
        "loss = torch.Tensor([2.0])\n",
        "epoch=0\n",
        "while (torch.abs(L_-loss)>1e-6) & (epoch <= num_epochs):# epoch in range(num_epochs):\n",
        "  optimizer2.zero_grad()\n",
        "  loss= v2.loss()#self.cost(self.X,self.modelu(X))+ torch.mean(self.terminal(update(self.X,self.modelu(X))))#\n",
        "  loss.backward()\n",
        "  optimizer2.step()\n",
        "  loss_epoch.append(loss)\n",
        "  if epoch>0:\n",
        "    L_ = loss_epoch[epoch-1]\n",
        "  if (epoch % 10==0):\n",
        "    print(\"At epoch {} the mean error is {}.\".format(epoch,loss.detach()))\n",
        "  epoch += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_6Swd47iUjw",
        "outputId": "e6c3bc8c-6d93-4a32-e8e0-3143ae2b0fb2"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch 0 the mean error is 0.0067556435242295265.\n",
            "At epoch 10 the mean error is 0.016793539747595787.\n",
            "At epoch 20 the mean error is 0.009750490076839924.\n",
            "At epoch 30 the mean error is 0.00776706775650382.\n",
            "At epoch 40 the mean error is 0.006860933266580105.\n",
            "At epoch 50 the mean error is 0.0067389607429504395.\n",
            "At epoch 60 the mean error is 0.0067915283143520355.\n",
            "At epoch 70 the mean error is 0.006707805674523115.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Value function"
      ],
      "metadata": {
        "id": "15SDOV4gHNjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8lyUL3ExAzX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.scatter(a.numpy(),b,s=5,label='vval2d T-5Delta t',marker='o');\n",
        "plt.scatter(x.clone().detach().numpy(),vval1(x).clone().detach().numpy(),s=5,label='vval1 T-5Delta t',marker='o');\n",
        "\n",
        "plt.legend();\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "2dnGfAOoAvOR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}