{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arashfahim/Stochastic_Control_FSU/blob/main/Deep_BSDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/arashfahim/Stochastic_Control_FSU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYpsD_vHtIpa",
        "outputId": "5dcbdf02-7a9e-4f3a-e95d-9c7278cb88ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Stochastic_Control_FSU'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 111 (delta 3), reused 2 (delta 2), pack-reused 97\u001b[K\n",
            "Receiving objects: 100% (111/111), 2.84 MiB | 6.56 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcK8F3qLthk9",
        "outputId": "c8a7e6f5-1bb9-4d54-90ab-4cee184755a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Dec  4 14:27 sample_data\n",
            "drwxr-xr-x 4 root root 4096 Dec  7 14:40 Stochastic_Control_FSU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'/content/Stochastic_Control_FSU/arashfahim/Stochastic_Control_FSU/'"
      ],
      "metadata": {
        "id": "gDKJJU8n5db3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix4wczxVvVD8",
        "outputId": "0204497b-d094-4889-84f7-e38910dcf118"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sotchastic control and BSDEs\n",
        "\n",
        "The goal of this notebook is to implement a BSDE dynamic programming principle, DPP, for a stochastic control problem.\n",
        "\n",
        "The stochastic control problem is given by\n",
        "\n",
        "$\\inf_{u}\\mathbb{E}\\bigg[\\int_{0}^{T}e^{-rt}C(t,X^u_t,u_t)dt+e^{-rT}g(X^u_T)\\bigg]$\n",
        "\n",
        "with\n",
        "\n",
        "$dX_t=\\mu(t,X^u_t,u_t)dt+\\sigma(t,X^u_t,u_t)dB_t$\n",
        "\n"
      ],
      "metadata": {
        "id": "Hq2eZ_d-UDNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assume that $\\sigma$ does not depend on $u$. When $\\sigma$ depends on $u$, the BSDE is second order and more involve.\n",
        "\n",
        "$dX^u_t=\\mu(t,X^u_t,u_t)dt+\\sigma(t,X^u_t)dB_t$\n",
        "\n",
        "The HJB is given by\n",
        "\n",
        "$\\begin{cases}\n",
        "\\partial_t V(t,x) + \\frac{\\sigma^2(t,x)}{2}\\partial^2_x V(t,x) -rV(t,x) + F(t,x,\\partial^2_x V(t,x))=0\\\\\n",
        "V(T,x)=g(x)\n",
        "\\end{cases}$\n",
        "\n",
        "where\n",
        "\n",
        "$F(t,x,p)=\\inf_u\\Big\\{C(t,x,u)+p\\mu(t,x,u)\\Big\\}$\n",
        "\n",
        "\n",
        "The BSDE is given by\n",
        "\n",
        "\n",
        "$Y_t=Y_T+\\int_t^T e^{-r(s-t)}\\Big(F(s,X_s,Z_s)dt-Z_s\\sigma(s,X_s)dB_s\\Big)$\n",
        "\n",
        "Or\n",
        "\n",
        "$\\begin{cases}\n",
        "dY_t=-F(t,X_t,Z_t)dt+Z_t\\sigma(t,X_t)dB_t\\\\\n",
        "Y_T=g(X_T)\n",
        "\\end{cases}$\n",
        "\n",
        "where $dX_t=\\sigma(t,X_t)dB_t$ is free of control.\n",
        "\n",
        "\n",
        "$Y_t$ and $Z_t$ are related to the solution to the HJB by $Y_t=V(t,X_t)$ and $Z_t=\\partial_x V(t,X_t)$.\n",
        "\n",
        "\n",
        "Note that here both $Y$ and $Z$ are unknowns. Particularly, $Y_0=V(0,X_0)$ is not known."
      ],
      "metadata": {
        "id": "JP7f4T78Uqvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical approximation of PDEs with BSDEs\n",
        "\n",
        "We discretize the BSDE:\n",
        "\n",
        "\n",
        "$\\begin{cases}\n",
        "Y_{t_{i+1}}= Y_{t_i}-F({t_i},X_{t_i},Z_{t_i})dt+Z_{t_i}\\sigma({t_i},X_{t_i})\\Delta B_{t_{t+1}}\\\\\n",
        "Y_T=g(X_T)\n",
        "\\end{cases}$\n",
        "\n",
        "where $X_{t_{i+1}}=X_{t_i}+\\sigma(t_i,X_{t_i})\\Delta B_{t_{t+1}}$\n",
        "\n",
        "If $\\hat{Y}$ is an approximate solution to the BSDE through the above method, $\\hat{Y}_{t_i}$ is an approximation of $V(t_i,X_{t_i})$. Specifically, if we start from  $\\hat{Y}_{0}$ and run the discretize BSDE forward, instead of backward, we must obtain $g(X_T)$ at time $T$.\n",
        "\n",
        "This is a basis for the deep numerical solution for the BSDE. Let's introduce two neural networks ${\\hat Y}_{t}=\\Phi(t,x;\\alpha)$ and ${\\hat Z}_{t}=\\Psi(t,x;\\beta)$.\n",
        "\n",
        "\n",
        "Then, simulate $X_0$ by some distribution and increment of Brownina motion to find sample paths through ${\\hat X}_{t_{i+1}}={\\hat X}_{t_i}+\\sigma(t_i,{\\hat X}_{t_i})\\Delta B_{t_{t+1}}$.\n",
        "\n",
        "Then, run the BSDE discretization forward in time:\n",
        "\n",
        "\n",
        "$\\Phi(t_{i+1},{\\hat X}_{t_{i+1}};\\alpha)= \\Phi(t_i,{\\hat X}_{t_{i}};\\alpha)-F\\big({t_i},{\\hat X}_{t_i},\\Psi({t_i},{\\hat X}_{t_i};\\beta)\\big)\\Delta t+\\Psi(t_{i},{\\hat X}_{t_i};\\beta)\\sigma({t_i},{\\hat X}_{t_i})\\Delta B_{t_{t+1}}$\n",
        "\n",
        "\n",
        "Finally, find optimal $\\alpha$ and $\\beta$ by\n",
        "\n",
        "$\\inf_{\\alpha,\\beta}\\mathbb{E}\\Big[\\Big(g({\\hat X}_T)-\\Phi_T({\\hat X}_{T};\\alpha)\\Big)\\Big]$"
      ],
      "metadata": {
        "id": "gWlxVOtcrwrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from time import strftime, localtime\n",
        "import torch.optim as optim #import optimizer\n",
        "# import torch.optim.lr_scheduler as lr_scheduler\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "M =10000# number of samples\n",
        "X = torch.normal(0., 1., size=(M,1))# samples for X~N(0,1)\n",
        "Y = torch.exp(-X)+torch.exp(X)*torch.normal(0., 1., size=(M,1))# samples for Y=e^{-x}+e^{x}N(0,1)\n",
        "# X.shape\n",
        "T=1# terminal horizon\n",
        "N = 10 # of time steps\n",
        "Dt= torch.Tensor([T/N])# time step size"
      ],
      "metadata": {
        "id": "-Obh3NNKOTMI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create time stamp to save the result\n",
        "stamp = strftime('%Y-%m-%d %H:%M:%S', localtime())\n",
        "print(str(stamp))"
      ],
      "metadata": {
        "id": "5hwEP5QcSA4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08cf5fa-715e-4d60-9f1e-5166fd8b180e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-07 14:41:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All at once"
      ],
      "metadata": {
        "id": "HQI-rsqSiGQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Z_NN(nn.Module):#multi_step, optimal_control\n",
        "    def __init__(self):\n",
        "        super(Z_NN, self).__init__()\n",
        "        self.layer = torch.nn.Sequential()\n",
        "        self.layer.add_module(\"L1\",torch.nn.Linear(2, 16))\n",
        "        self.layer.add_module(\"Tanh\", torch.nn.Tanh())\n",
        "        self.layer.add_module(\"L2\",torch.nn.Linear(16,1))\n",
        "    def forward(self, tx):\n",
        "        val = self.layer(tx)\n",
        "        return val"
      ],
      "metadata": {
        "id": "SIpEW8y9ztpK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Y_NN(nn.Module):#multi_step, optimal_control\n",
        "    def __init__(self):\n",
        "        super(Y_NN, self).__init__()\n",
        "        self.layer = torch.nn.Sequential()\n",
        "        self.layer.add_module(\"L1\",torch.nn.Linear(1, 16))\n",
        "        self.layer.add_module(\"Tanh\", torch.nn.Tanh())\n",
        "        self.layer.add_module(\"L2\",torch.nn.Linear(16,1))\n",
        "    def forward(self, tx):\n",
        "        val = self.layer(tx)\n",
        "        return val"
      ],
      "metadata": {
        "id": "LVLBBho925O3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BSDE(classmethod):#multi_step, optimal_control\n",
        "    def __init__(self,terminal):\n",
        "        self.Y_NN = Y_NN()\n",
        "        self.Z_NN = Z_NN()\n",
        "        self.M = 1000# number of samples\n",
        "        self.Te=1.0 # terminal time\n",
        "        self.K = 20 # total number of steps\n",
        "        self.Dt= torch.Tensor([self.Te/self.K]) #time step\n",
        "        self.num_steps = 5 #number of steps to evaluate <= self.K\n",
        "        # self.N = torch.normal(0., 1., size=[self.M,self.num_steps,1])\n",
        "        self.terminal = terminal # terminal value function\n",
        "        self.X0 = torch.normal(0., 1., size=(self.M,1))\n",
        "        for i in range(self.K):# create time data points\n",
        "            if i == 0:\n",
        "                T = torch.Tensor([0.0]).repeat([self.M,1])\n",
        "            else:\n",
        "                D = i*self.Dt# time step i\n",
        "                T = torch.cat((T,D.repeat([self.M,1])),axis=1)\n",
        "        self.T = T.unsqueeze(2)\n",
        "        self.B = torch.normal(0., 1., size=(self.M,self.K,1))\n",
        "        for i in range(self.K-self.num_steps,self.K):\n",
        "                if i == self.K-self.num_steps:\n",
        "                    update = torch.cat((self.T[:,i],self.X0),axis=1)# cat time and space\n",
        "                    self.TX = update.unsqueeze(-1) # add dimension fot bmm\n",
        "                else:\n",
        "                    X = update[:,1].unsqueeze(-1)# slice space for update\n",
        "                    X = X +  torch.sqrt(self.Dt)*self.B[:,i-1] #update, += is prohibited here because it fundamentally change\n",
        "                    update = torch.cat((self.T[:,i],X),axis=1) # cat  time and space\n",
        "                    self.TX = torch.cat((self.TX,update.unsqueeze(-1)),axis=-1) # cat to previous data\n",
        "        X = update[:,1].unsqueeze(-1) #slice last space\n",
        "        X = X +  torch.sqrt(self.Dt)*self.B[:,-1]# last update, += is prohibited here\n",
        "        update = torch.cat((torch.Tensor([self.Te]).repeat([self.M,1]),X),axis=1) # last cat\n",
        "        self.TX = torch.cat((self.TX,update.unsqueeze(-1)),axis=-1) #last cat to previous data\n",
        "\n",
        "    def F(self,tx):#take a [N,1] tensor\n",
        "        # tx = torch.cat((t,x),axis=1)\n",
        "        return torch.Tensor([0.5])*torch.pow(self.Z_NN.forward(tx),2)-self.Z_NN.forward(tx)*(tx[:,1].unsqueeze(-1))\n",
        "\n",
        "    def loss(self):\n",
        "        for i in range(self.K-self.num_steps,self.K):\n",
        "                if i == self.K-self.num_steps:\n",
        "                    # print(self.TX[:,1,0].shape)\n",
        "                    Y = self.Y_NN(self.TX[:,1,0].unsqueeze(-1))\n",
        "                else:\n",
        "                    # print(self.TX[:,:,i-self.K+self.num_steps].shape,self.Z_NN(self.TX[:,:,i-self.K+self.num_steps]).shape,self.B[:,i-1].shape)\n",
        "                    Y = Y + self.F(self.TX[:,:,i-self.K+self.num_steps])*self.Dt + self.Z_NN(self.TX[:,:,i-self.K+self.num_steps])*self.B[:,i-1]\n",
        "        Y = Y + self.F(self.TX[:,:,-1])*self.Dt + self.Z_NN(self.TX[:,:,-1])*self.B[:,-1]\n",
        "        return torch.mean(torch.pow(self.terminal(self.TX[:,1,-1]).unsqueeze(-1)-Y,2)) #mean value of running and terminal\n",
        "\n",
        "    # def value(self):# to evaluate value function through conditional expectation\n",
        "    #     if self.value:\n",
        "    #         # print(\"I exist.\")\n",
        "    #         for i in range(self.K-self.num_steps,self.K):\n",
        "    #             if i == self.K-self.num_steps:\n",
        "    #                 update = torch.cat((self.T[:,i],self.X0),axis=1)# cat time and space\n",
        "    #                 self.TX = update.unsqueeze(-1) # add dimension fot bmm\n",
        "    #             else:\n",
        "    #                 X = update[:,1].unsqueeze(-1)# slice space for update\n",
        "    #                 X = X + (-X+self.forward(update))*self.Dt + torch.sqrt(self.Dt)*self.B[:,i-1] #update, += is prohibited here because it fundamentally change\n",
        "    #                 update = torch.cat((self.T[:,i],X),axis=1) # cat  time and space\n",
        "    #                 self.TX = torch.cat((self.TX,update.unsqueeze(-1)),axis=-1) # cat to previous data\n",
        "    #         X = update[:,1].unsqueeze(-1) #slice last space\n",
        "    #         X = X + (-X+self.forward(update))*self.Dt + torch.sqrt(self.Dt)*self.B[:,-1]# last update, += is prohibited here\n",
        "    #         update = torch.cat((torch.Tensor([self.Te]).repeat([self.M,1]),X),axis=1) # last cat\n",
        "    #         self.TX = torch.cat((self.TX,update.unsqueeze(-1)),axis=-1) #last cat to previous data\n",
        "    # #       cost along the path\n",
        "    #         temp_cost = self.terminal(X)  # termial cost\n",
        "    #         # self.Y = temp_cost.unsqueeze(-1)# add dimension\n",
        "    #         # for i in reversed(range(self.K-self.num_steps,self.K)):# backward loop for cost evaluation\n",
        "    #         #         temp_cost = temp_cost + self.Dt*self.cost(update)# accumulation of cost for new point+= is prohibited here\n",
        "    #         #         self.Y = torch.cat((temp_cost.unsqueeze(1),self.Y),axis=-1) #backward cat of cost\n",
        "    #     # self.value_flag = False\n"
      ],
      "metadata": {
        "id": "bnapNc3rf26o"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class terminal(nn.Module):\n",
        "    def __init__(self,flag,*args):\n",
        "        super(terminal, self).__init__()\n",
        "        self.layer = torch.nn.Sequential()\n",
        "        self.layer.add_module(\"L1\",torch.nn.Linear(1, 16))\n",
        "        self.layer.add_module(\"Tanh\", torch.nn.Tanh())\n",
        "        self.layer.add_module(\"L2\",torch.nn.Linear(16,1))\n",
        "        self.flag = flag\n",
        "    def forward(self, x):\n",
        "        if self.flag == 'T':\n",
        "            return torch.Tensor([0.5])*torch.pow(x,2)-x\n",
        "        else:\n",
        "            val = self.layer(x)\n",
        "            return val\n",
        "        return x"
      ],
      "metadata": {
        "id": "bDi5DZgc5DT9"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = terminal('T')\n",
        "v2 = BSDE(g)\n",
        "# v2.value()"
      ],
      "metadata": {
        "id": "arVD0owsiSYM"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.autograd.set_detect_anomaly(True);"
      ],
      "metadata": {
        "id": "i_O95kDKki9s"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_epoch = []\n",
        "num_epochs = 500\n",
        "lr = 1e-2\n",
        "parameters = list(v2.Y_NN.parameters()) + list(v2.Z_NN.parameters())\n",
        "optimizer2 = optim.Adam(parameters, lr)\n",
        "L_ = torch.Tensor([-2.0])\n",
        "loss = torch.Tensor([2.0])\n",
        "epoch=0\n",
        "while (torch.abs(L_-loss)>1e-6) & (epoch <= num_epochs):# epoch in range(num_epochs):\n",
        "  optimizer2.zero_grad()\n",
        "  loss= v2.loss()#self.cost(self.X,self.modelu(X))+ torch.mean(self.terminal(update(self.X,self.modelu(X))))#\n",
        "  loss.backward()\n",
        "  optimizer2.step()\n",
        "  loss_epoch.append(loss)\n",
        "  if epoch>0:\n",
        "    L_ = loss_epoch[epoch-1]\n",
        "  if (epoch % 10==0):\n",
        "    print(\"At epoch {} the mean error is {}.\".format(epoch,loss.detach()))\n",
        "  epoch += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_6Swd47iUjw",
        "outputId": "b09da343-12f3-4b52-cf54-a2cc17bb1442"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch 0 the mean error is 0.011331615969538689.\n",
            "At epoch 10 the mean error is 0.013535451143980026.\n",
            "At epoch 20 the mean error is 0.01122268009930849.\n",
            "At epoch 30 the mean error is 0.011156030930578709.\n",
            "At epoch 40 the mean error is 0.01025847252458334.\n",
            "At epoch 50 the mean error is 0.010027095675468445.\n",
            "At epoch 60 the mean error is 0.009736089035868645.\n",
            "At epoch 70 the mean error is 0.00954276043921709.\n",
            "At epoch 80 the mean error is 0.00934978574514389.\n",
            "At epoch 90 the mean error is 0.009161205030977726.\n",
            "At epoch 100 the mean error is 0.008983644656836987.\n",
            "At epoch 110 the mean error is 0.008815818466246128.\n",
            "At epoch 120 the mean error is 0.008658011443912983.\n",
            "At epoch 130 the mean error is 0.008510076440870762.\n",
            "At epoch 140 the mean error is 0.008372176438570023.\n",
            "At epoch 150 the mean error is 0.008244001306593418.\n",
            "At epoch 160 the mean error is 0.008125181309878826.\n",
            "At epoch 170 the mean error is 0.008015250787138939.\n",
            "At epoch 180 the mean error is 0.007913713343441486.\n",
            "At epoch 190 the mean error is 0.00782003067433834.\n",
            "At epoch 200 the mean error is 0.0077336570248007774.\n",
            "At epoch 210 the mean error is 0.007654048502445221.\n",
            "At epoch 220 the mean error is 0.007580701727420092.\n",
            "At epoch 230 the mean error is 0.007513117976486683.\n",
            "At epoch 240 the mean error is 0.007450832054018974.\n",
            "At epoch 250 the mean error is 0.0073934015817940235.\n",
            "At epoch 260 the mean error is 0.007340441923588514.\n",
            "At epoch 270 the mean error is 0.007291554473340511.\n",
            "At epoch 280 the mean error is 0.007246393710374832.\n",
            "At epoch 290 the mean error is 0.007204641122370958.\n",
            "At epoch 300 the mean error is 0.007165991701185703.\n",
            "At epoch 310 the mean error is 0.0071301707066595554.\n",
            "At epoch 320 the mean error is 0.007096931338310242.\n",
            "At epoch 330 the mean error is 0.007066037505865097.\n",
            "At epoch 340 the mean error is 0.007037276867777109.\n",
            "At epoch 350 the mean error is 0.0070104594342410564.\n",
            "At epoch 360 the mean error is 0.0069854166358709335.\n",
            "At epoch 370 the mean error is 0.006961986422538757.\n",
            "At epoch 380 the mean error is 0.006940031889826059.\n",
            "At epoch 390 the mean error is 0.00691943196579814.\n",
            "At epoch 400 the mean error is 0.006900070700794458.\n",
            "At epoch 410 the mean error is 0.00688184704631567.\n",
            "At epoch 420 the mean error is 0.006864671129733324.\n",
            "At epoch 430 the mean error is 0.006848463788628578.\n",
            "At epoch 440 the mean error is 0.006833146326243877.\n",
            "At epoch 450 the mean error is 0.006818658672273159.\n",
            "At epoch 460 the mean error is 0.006804937031120062.\n",
            "At epoch 470 the mean error is 0.006791929714381695.\n",
            "At epoch 480 the mean error is 0.006779592949897051.\n",
            "At epoch 490 the mean error is 0.006767870858311653.\n",
            "At epoch 500 the mean error is 0.006756727118045092.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2.value()"
      ],
      "metadata": {
        "id": "09TI7oFgARx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape TX and Y\n",
        "TX = torch.cat((v2.TX[:,0,:].clone().detach().reshape(-1).unsqueeze(-1),v2.TX[:,1,:].clone().detach().reshape(-1).unsqueeze(-1)),axis=-1).clone().detach()\n",
        "TX.shape,v2.Y.reshape(-1).shape"
      ],
      "metadata": {
        "id": "kzh3Q1dqAac-",
        "outputId": "593b7b95-9f75-4620-bcbd-a879f3888440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6000, 2]), torch.Size([6000]))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2.TX[:,:,-1].shape, v2.Y[:,:,-1][:,0].shape"
      ],
      "metadata": {
        "id": "3AZpbisZMqLy",
        "outputId": "bb87902e-3997-46de-9c9c-fb0f4c0eaa1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1000, 2]), torch.Size([1000]))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Value function"
      ],
      "metadata": {
        "id": "15SDOV4gHNjJ"
      }
    }
  ]
}